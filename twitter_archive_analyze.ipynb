{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Archive includes a csv of tweets, so we'll use that\n",
    "\n",
    "##### Simple Cleanse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv is in poor shape, and we need to strip some newline data\n",
    "fname = \"../archive_dec16/tweets.csv\"\n",
    "cname = \"../archive_dec16/cleantweets.csv\"\n",
    "\n",
    "# how we want to clean some srings (uses reduce)\n",
    "repls = {'\\n': '', ',':''}\n",
    "\n",
    "def string_clean(text):\n",
    "    for i, j in repls.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "with open(fname, \"r\", encoding=\"utf8\") as input, open(cname, \"w\", encoding='utf-8', newline='') as output:\n",
    "    w = csv.writer(output)\n",
    "    for record in csv.reader(input):\n",
    "        clean_row = tuple(string_clean(s) for s in record)\n",
    "        # in this simple example we only care for timestamp & text\n",
    "        w.writerow((clean_row[3],clean_row[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and transform data\n",
    "\n",
    "we need to transform the data into relevant info for this example, something like:  \n",
    "\n",
    "  <p style=\"text-align: center;\">date : <em>tweeting score</em> </p>\n",
    "  \n",
    "  tweeting score will include a total count of tweets as well as total words for the day, for now it'll just be a simple calculation\n",
    "  \n",
    "  <p style=\"text-align: center;\"><em>single day tweeting score</em> = total tweets + total words </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n",
      "[(datetime.datetime(2018, 12, 16, 0, 0),  29)\n",
      " (datetime.datetime(2018, 12, 16, 0, 0),  51)\n",
      " (datetime.datetime(2018, 12, 16, 0, 0), 206)\n",
      " (datetime.datetime(2018, 12, 13, 0, 0),  57)\n",
      " (datetime.datetime(2018, 12, 10, 0, 0),  89)\n",
      " (datetime.datetime(2018, 12, 10, 0, 0),  60)\n",
      " (datetime.datetime(2018, 12, 9, 0, 0),  56)\n",
      " (datetime.datetime(2018, 12, 9, 0, 0),  63)\n",
      " (datetime.datetime(2018, 12, 9, 0, 0),  43)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dealing with timestamps so we'll need to convert\n",
    "str2date = lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S %z')\n",
    "str2int = lambda x: len(x)\n",
    "\n",
    "tweet_data = np.genfromtxt(cname, dtype=None, delimiter=',',\n",
    "                           skip_header=1,\n",
    "                           converters = {0: str2date,1: str2int},\n",
    "                           encoding=\"utf8\")\n",
    "\n",
    "num_tweets = len(tweet_data)\n",
    "    \n",
    "print(num_tweets)\n",
    "print(tweet_data[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape looks right (I haven't hit the 1k mark yet...), now we need to aggregate all of the same-day tweets and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 235\n"
     ]
    }
   ],
   "source": [
    "agg_data = {}# simple dates\n",
    "\n",
    "for item in tweet_data:\n",
    "    key = item[0].strftime('%m/%d/%Y')\n",
    "    if key in agg_data:\n",
    "        agg_data[key] = agg_data[key] + item[1]\n",
    "    else:\n",
    "        agg_data[key] = item[1]\n",
    "\n",
    "dates = np.array(list(agg_data.keys()))\n",
    "tscores = np.array(list(agg_data.values()))\n",
    "\n",
    "# \n",
    "print(len(dates), len(tscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
